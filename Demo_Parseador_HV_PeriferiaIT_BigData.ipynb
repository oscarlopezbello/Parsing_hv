{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo_Parseador_HV_PeriferiaIT_BigData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oscarlopezbello/Parsing_hv/blob/main/Demo_Parseador_HV_PeriferiaIT_BigData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0C-4tw_Mn0P"
      },
      "source": [
        "## DEMO PARSEADOR HOJAS DE VIDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm7ZlfIlMyjr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKb95ss8Nv_3"
      },
      "source": [
        "En este demo se busca realizar una demostracíon de como se puede extraer la información de una hoja de vida contando con unos parametros de entrada en formato json. la hoja de vida de referencia esta en el siguiente link [Hoja de Vida Referencia](https://drive.google.com/file/d/1l0P5Wgsay-e8s7HQ_eNi6as94hDf4k5a/view?usp=sharing). Este codigo se encarga de recibir estos parametros de entrada en formato json como lo pueden ser: \r\n",
        "1. sueldo \r\n",
        "2. conocimientos en lenguajes o tecnologias especificas.\r\n",
        "3. Idiomas que domine el candidato.\r\n",
        "4. Si cuenta o no con tarjeta profesional registrada en su hoja de vida.\r\n",
        "5. Estudios especificos en algun campo que se requiera.\r\n",
        "\r\n",
        "La funcion parsing_hv se encarga de procesar estos requisitos y devolver un json nuevo con los campos que cumpla la personas, adicionalmente de entregar otros datos de la hoja de vida que para este demo son:\r\n",
        "\r\n",
        "1. Nombre del Candidato.\r\n",
        "2. Experiencia con la que cuenta en la hoja de vida.\r\n",
        "3. edad del candidato.\r\n",
        "4. Si cuenta o no con tarjeta profesional registrada en su hoja de vida.\r\n",
        "5. Sueldo o aspiracion Salarial registrada en la hoja de vida del candidato.\r\n",
        "6. Conocimientos esecificos con los que cuente la persona en: Bases de Datos, Lengiajes de Programación, frameworks, herramientas de Nube. Estos campos se retornaran vacios en caso que el candidato no cuente con alguna de estas habilidades o conocimientos.\r\n",
        "7. Idiomas que maneje y registre en su hoja de vida segun requerimiento de entrada. \r\n",
        "8. Estudios que maneje y registre en su hoja de vida segun requerimiento de entrada. \r\n",
        "9. Una ponderación en porcentaje de coincidencia de los valores solcitidados contra los valores o requisitos encontrados en la hoja de vida, esto expresado en un procentaje sobre un 100%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "popKg4_eVWIG"
      },
      "source": [
        "A continuacion se Explica un paso a paso de como funciona este codigo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ydJc-QoNtQ5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGDpZhIcIy8L"
      },
      "source": [
        "import json\r\n",
        "import nltk\r\n",
        "import re\r\n",
        "import os\r\n",
        "from datetime import datetime\r\n",
        "import base64\r\n",
        "from pathlib import Path\r\n",
        "from google.colab import drive"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYgwL1NqHBtB"
      },
      "source": [
        "## Se realiza importación de libreria para poder importar el fichero desde ubicación drive para efectos del demo.\r\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AyTn0f6I8VH"
      },
      "source": [
        "def parsing_hv (json_frontend):\r\n",
        "\r\n",
        "    def nombre_candidato (cadena):\r\n",
        "        tags = nltk.pos_tag(nltk.word_tokenize(cadena))\r\n",
        "        nouns = [(word, tag) for word, tag in tags if tag in ['NN','NNS', 'NNP', 'NNPS']]\r\n",
        "        nombres = nouns[0:3]\r\n",
        "        nombre = \"\"\r\n",
        "        for x in nombres:\r\n",
        "            a=\"\".join(x)\r\n",
        "            nombre = nombre+a+\"\"\r\n",
        "            nombre = nombre.replace(\"NNP\", \" \").replace(\"\\uf095\",\"\").replace(\"Ingeniería\", \"\").replace(\"NNS\",\" \").replace(\"\\uf00c\",\"\").replace(\"NN\",\" \")\r\n",
        "        return nombre\r\n",
        "\r\n",
        "    def read_file(path):\r\n",
        "        items = []\r\n",
        "        f = open(path)\r\n",
        "        for x in f:\r\n",
        "            items.append(str(x.replace('\\n','')))\r\n",
        "        f.close()\r\n",
        "        return items\r\n",
        "\r\n",
        "    def habilidades (habilidad, string_json, texto):\r\n",
        "        lista = []\r\n",
        "        for a in habilidad:\r\n",
        "            a = a.lower()\r\n",
        "            a = a.strip()\r\n",
        "            if a in texto:\r\n",
        "                lista.append(a)\r\n",
        "        json_hv[string_json] = lista\r\n",
        "            \r\n",
        "    def coincidencias(busqueda, json_hv):\r\n",
        "        set_parametros = set()\r\n",
        "        total_encontrado = 0\r\n",
        "        set_valores = set()\r\n",
        "        dicc_parametros = {}\r\n",
        "        for key in busqueda.keys():\r\n",
        "            set_valores.add(key)\r\n",
        "        \r\n",
        "        for key, value in busqueda.items():\r\n",
        "            lista=[]\r\n",
        "            if type(value) == list:\r\n",
        "                for i in value:\r\n",
        "                    if i == \"No aplica\":\r\n",
        "                        set_valores.remove(key)\r\n",
        "                    lista.append(i.lower())\r\n",
        "                        \r\n",
        "                if len(value) == 0:\r\n",
        "                    set_valores.remove(key)\r\n",
        "                elif key in set_valores:\r\n",
        "                    dicc_parametros[key] = len(value)\r\n",
        "                busqueda[key]=lista   \r\n",
        "                \r\n",
        "        ponderacion = 100 / len(set_valores)\r\n",
        "\r\n",
        "        for key, value in json_hv.items():\r\n",
        "            contador = 0\r\n",
        "            if key in set_valores:\r\n",
        "            \r\n",
        "                for i in value:\r\n",
        "                    if str(i).lower() in busqueda[key]:\r\n",
        "                        contador += 1\r\n",
        "                dicc_parametros[key] = (dicc_parametros[key], contador)\r\n",
        "\r\n",
        "        coincidencia = 0\r\n",
        "        for key, value in dicc_parametros.items():\r\n",
        "            coincidencia += (value[1] / value[0]) * ponderacion    \r\n",
        "        return coincidencia\r\n",
        "\r\n",
        "    def hv_base64 (ruta):\r\n",
        "        data = open(ruta, \"rb\").read()\r\n",
        "        encoded = base64.b64encode(data)\r\n",
        "        hv_base64 = encoded.decode('utf-8')\r\n",
        "        return hv_base64\r\n",
        "        \r\n",
        "    parametros = json_frontend\r\n",
        "    \r\n",
        "    bases_datos = parametros[\"bases_de_datos\"]\r\n",
        "    lenguajes_programacion = parametros[\"lenguajes_de_programacion\"] \r\n",
        "    frameworks = parametros[\"frameworks\"]\r\n",
        "    servicios_nube = parametros[\"nube\"]\r\n",
        "    cargos = parametros[\"cargos\"]\r\n",
        "    idiomas = parametros[\"idiomas\"]\r\n",
        "    estudios = parametros[\"estudios\"]\r\n",
        "    tarjeta = parametros[\"tarjeta_profesional\"]\r\n",
        "    sueldo = parametros[\"sueldo\"]\r\n",
        "\r\n",
        "    files = []\r\n",
        "    for file in os.listdir(\"https://github.com/oscarlopezbello/Parsing_hv.git\"):\r\n",
        "        if file.endswith(\".txt\"):\r\n",
        "            files.append(\"https://github.com/oscarlopezbello/Parsing_hv.git\" + \"/\" + file)\r\n",
        "\r\n",
        "    lista_json = []\r\n",
        "    for file in files:\r\n",
        "        documento = open(file,encoding='utf-8')\r\n",
        "        documento_txt = str(documento.read())\r\n",
        "        json_hv = {}\r\n",
        "        texto_limpio = \"\"\r\n",
        "        \r\n",
        "        filename = Path(file).stem\r\n",
        "        ruta_pdf= \"https://github.com/oscarlopezbello/Parsing_hv.git\"\r\n",
        "        link_hv = f\"{ruta_pdf}/{filename}.pdf\"\r\n",
        "        hv_encoded = hv_base64(link_hv)\r\n",
        "        #json_hv[\"hv_base64\"] = hv_encoded\r\n",
        "\r\n",
        "        for b in documento_txt:\r\n",
        "            b = b.replace(\"\\uf00c\",\" \").replace(\"\\uf041\",\" \").replace(\"\\uf003\",\" \").replace(\"\\uf095\",\" \").replace(\"\\uf19c\",\" \")\r\n",
        "            b = b.rstrip()\r\n",
        "            b = b.lstrip()\r\n",
        "            b = b.strip()\r\n",
        "            texto_limpio = texto_limpio + b\r\n",
        "        nombre = nombre_candidato(documento_txt)\r\n",
        "        json_hv[\"nombre\"] = nombre\r\n",
        "        print(json_hv[\"nombre\"])\r\n",
        "        texto_limpio_base = texto_limpio.lower()\r\n",
        "\r\n",
        "        exp_temp=re.findall(\"[a-zA-Z0-9_]* [0-9]{4} - [a-zA-Z0-9_]* [0-9]{4}\",documento_txt.lower() )\r\n",
        "        fechas_experiencias=[]\r\n",
        "        for a in exp_temp:\r\n",
        "            a = a.replace(\"enero\",\"01\").replace(\"febrero\",\"02\").replace(\"marzo\",\"03\").replace(\"abril\",\"04\").replace(\"mayo\",\"05\").replace(\"junio\",\"06\").replace(\"julio\",\"07\").replace(\"agosto\",\"08\").replace(\"septiembre\",\"09\").replace(\"octubre\",\"10\").replace(\"noviembre\",\"11\").replace(\"diciembre\",\"12\")\r\n",
        "            a = a.split(\" - \")\r\n",
        "            fechas_experiencias = fechas_experiencias + a\r\n",
        "        fechas_experiencias1=[]\r\n",
        "        for lista in fechas_experiencias:    \r\n",
        "            lista= lista.replace(\" \",\"/01/\").replace(\"/20\", \"/\").replace(\"/199\", \"/9\").replace(\"/198\",\"/8\")\r\n",
        "            fechas_experiencias1 = fechas_experiencias1 + [lista]\r\n",
        "        try:\r\n",
        "\r\n",
        "            if len(fechas_experiencias1)>3:\r\n",
        "                strDate = fechas_experiencias1[-2]\r\n",
        "                date2 = fechas_experiencias1[0]\r\n",
        "                objDate = datetime.strptime(strDate, '%m/%d/%y')\r\n",
        "                objDate1 = datetime.strptime(date2, '%m/%d/%y')\r\n",
        "                total = (objDate1 - objDate)/365\r\n",
        "                experiencia_total = total.days\r\n",
        "                json_hv[\"experiencia\"] = str(experiencia_total)\r\n",
        "            else:\r\n",
        "                json_hv[\"experiencia\"] = \"no cuenta con tiempo de experiencias\"\r\n",
        "\r\n",
        "        except IOError as e:\r\n",
        "            json_hv[\"experiencia\"] = \"no cuenta con tiempo de experiencias\"\r\n",
        "\r\n",
        "\r\n",
        "        edad=re.findall(\"[|] [0-9]{2} años\",documento_txt )\r\n",
        "        edad = \"\".join(edad).replace(\"| \",\"\").replace(\" años\",\"\")\r\n",
        "        json_hv[\"edad\"] = edad\r\n",
        "        \r\n",
        "\r\n",
        "        for t in tarjeta:\r\n",
        "            if t ==\"si\":\r\n",
        "                if \"tarjeta profesional\" in documento_txt:\r\n",
        "                    json_hv[\"tarjeta_profesional\"] = \"si\"\r\n",
        "                elif \"t.p\" in texto_limpio_base:\r\n",
        "                    json_hv[\"tarjeta_profesional\"] = \"si\"\r\n",
        "                else:\r\n",
        "                    json_hv[\"tarjeta_profesional\"] = \"\"\r\n",
        "            else:\r\n",
        "                json_hv[\"tarjeta_profesional\"] = \"\"    \r\n",
        "\r\n",
        "                    \r\n",
        "        sueldo_hv = re.findall(\"[$][0-9]{1} A [$][0-9]{1}\" or \"[$][0-9]{1}[,][0-9]{1} A [$][0-9]{1}[,][0-9]{1}\",documento_txt ) \r\n",
        "        if len(sueldo_hv)>0:\r\n",
        "            sueldo_hv = \"\".join(sueldo_hv).replace(\"$\",\"\")\r\n",
        "            sueldo_hv = sueldo_hv[-1]\r\n",
        "            for i in sueldo:\r\n",
        "                if i<sueldo_hv:\r\n",
        "                    json_hv[\"sueldo\"] = \"\"\r\n",
        "                else:\r\n",
        "                    json_hv[\"sueldo\"] = sueldo_hv \r\n",
        "        else:\r\n",
        "            json_hv[\"sueldo\"] = \"no cuenta con aspiracion salarial\"\r\n",
        "\r\n",
        "        habilidades(bases_datos,\"bases_de_datos\",texto_limpio_base)\r\n",
        "        habilidades(lenguajes_programacion,\"lenguajes_de_programacion\",texto_limpio_base)\r\n",
        "        habilidades(frameworks,\"frameworks\",texto_limpio_base)\r\n",
        "        habilidades(servicios_nube,\"nube\",texto_limpio_base)\r\n",
        "        habilidades(cargos,\"cargos\",documento_txt)\r\n",
        "        habilidades(idiomas,\"idiomas\",texto_limpio_base)\r\n",
        "        habilidades(estudios,\"estudios\",texto_limpio_base)\r\n",
        "        \r\n",
        "        json_hv[\"porcentaje_coincidencias\"] = str(coincidencias(parametros, json_hv))\r\n",
        "        lista_json.append(json_hv)  \r\n",
        "        \r\n",
        "    return lista_json"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ_i6R6tVlpE"
      },
      "source": [
        "with open('/content/jsonprueba.json') as f:\r\n",
        "    json_entrada = json.load(f)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSFXsJYUV0qE",
        "outputId": "00d97f64-4c3c-4faf-9c9f-10fa7967c322"
      },
      "source": [
        "json_entrada"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bases_de_datos': ['Oracle', 'sql'],\n",
              " 'cargos': ['Arquitecto de soluciones'],\n",
              " 'estudios': ['Abbyy Advanced Training'],\n",
              " 'experiencia': ['4'],\n",
              " 'frameworks': ['react'],\n",
              " 'idiomas': ['Ingles'],\n",
              " 'lenguajes_de_programacion': ['Java'],\n",
              " 'nube': ['AWS'],\n",
              " 'sueldo': ['7'],\n",
              " 'tarjeta_profesional': ['si']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "hk9H3m_RW37V",
        "outputId": "9e6fc96c-6408-4ebb-df33-528b3283022e"
      },
      "source": [
        "parsing_hv(json_entrada)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7f22b1d15c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsing_hv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_entrada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-349d5a2985f1>\u001b[0m in \u001b[0;36mparsing_hv\u001b[0;34m(json_frontend)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/oscarlopezbello/Parsing_hv.git\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/oscarlopezbello/Parsing_hv.git\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://github.com/oscarlopezbello/Parsing_hv.git'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm9BcG6jy9OA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}